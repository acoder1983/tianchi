{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_events=pd.read_csv('raw_data/tianchi_fresh_comp_train_user.csv')\n",
    "part_events=pd.read_csv('raw_data/partial_events.csv')\n",
    "all_items=pd.read_csv('raw_data/tianchi_fresh_comp_train_item.csv')\n",
    "target_items=set(all_items.item_id)\n",
    "action_types=['browsed','collected','carted','bought']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'total events count %d, total users %d' % (len(all_events), len(all_events.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'total user item pair %d' % len(all_events.groupby(['user_id','item_id']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'total buy events %d' % len(all_events[all_events.behavior_type==4].groupby(['user_id','item_id']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sample users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users=all_events.user_id.unique()\n",
    "sample_users=all_users[:500]\n",
    "sample_events=all_events[all_events.user_id.apply(lambda uid:uid in sample_users)]\n",
    "len(sample_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_events.item_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behaves=sample_events[['user_id','item_id','behavior_type','time']].pivot_table(index=['user_id','item_id'],columns='behavior_type',aggfunc='count').fillna(0)\n",
    "behaves.columns=action_types\n",
    "buy_behaves=behaves[behaves.bought>0]\n",
    "len(behaves),len(buy_behaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nbuy_behaves=behaves[behaves.bought==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_behaves.index.levels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### will events happen before buy sth in n days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_events['time']=pd.DatetimeIndex(sample_events.time)\n",
    "buy_events=sample_events[sample_events.behavior_type==4]\n",
    "nbuy_events=sample_events[sample_events.behavior_type!=4]\n",
    "\n",
    "n_days=1\n",
    "buy_events['before_n']=buy_events.apply(lambda e:len(nbuy_events[(nbuy_events.user_id==e.user_id)&(nbuy_events.item_id==e.item_id)&(nbuy_events.time<e.time)]), axis=1)\n",
    "len(buy_events),len(buy_events[buy_events.before_n==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems half not-buy events happen in the same day with the buy event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_size=len(all_items)\n",
    "cat_size=len(all_items.item_category.unique())\n",
    "geo_size=len(all_items.item_geohash.unique())\n",
    "'recommend items %d, types %d, geo %d' % (item_size,cat_size,geo_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'geo missing %.4f'%(1-all_items.item_geohash.count()/len(all_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is every category equal size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_summ=all_items.groupby('item_category').count()[['item_id']].sort_values('item_id',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cate_summ.hist(cumulative=True,normed=1,figsize=(20,5),bins=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'only has 1 item categories %d' % (len(cate_summ[cate_summ.item_id==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'cate size avg %d, mid %d' %(item_size)//cat_size, cate_summ.iloc[cat_size//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'top 10 items ratio %.2f, top 100 %.2f' % (np.sum(cate_summ[:10])/item_size, np.sum(cate_summ[:100])/item_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_items=set(all_events.item_id.unique())\n",
    "'target_items_in_train / target_items: %.2f ' % (len(list(filter(lambda i: i in train_items, target_items)))/len(target_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## user_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'%d items in train events ' % len(all_events.item_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is everyday's events num equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part_events['day']=part_events.time.apply(lambda t:pd.Timestamp(year=t.year,month=t.month,day=t.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "part_events.groupby('day').count()[['time']].plot(kind='bar',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems the last day's data is normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### is all buy items in target items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buy_events=part_events[part_events.behavior_type==4]\n",
    "\n",
    "'in target ratio %.2f' % (len(buy_events[buy_events.item_id.apply(lambda i:i in target_items)]) / len(buy_events))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target items are part of everyday buy items "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### before a user buy one item, will he view similar items day before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_sim_visits(during):\n",
    "    obs_day=pd.Timestamp(year=2014,month=11,day=19)\n",
    "    chk_day=obs_day+pd.Timedelta(during,'d')\n",
    "\n",
    "    obs_events=part_events[(part_events.time>=obs_day)&(part_events.time<chk_day)]\n",
    "    buy_events=part_events[(part_events.behavior_type==4)&(part_events.time>=chk_day)&(part_events.time<chk_day+pd.Timedelta(1,'d'))] \\\n",
    "        [lambda df:df.item_id.apply(lambda i:i in target_items)]\n",
    "\n",
    "    buy_times=len(buy_events)\n",
    "    sim_visits=len(obs_events[lambda df:df.apply(lambda e: len(buy_events[\n",
    "        (buy_events.user_id==e.user_id)&(buy_events.item_category==e.item_category)])>0,axis=1)])\n",
    "\n",
    "    print('%ddays, buy %d, similar visits %d, ratio %.2f' % (during, buy_times, sim_visits, buy_times/sim_visits))\n",
    "\n",
    "for d in range(1,4):\n",
    "    count_sim_visits(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25% similar items will be bought next day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### before buy one item, will user be active days before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def count_active_users(during):\n",
    "    obs_day=pd.Timestamp(year=2014,month=11,day=19)\n",
    "    chk_day=obs_day+pd.Timedelta(during,'d')\n",
    "\n",
    "    obs_events=part_events[(part_events.time>=obs_day)&(part_events.time<chk_day)]\n",
    "    buy_events=part_events[(part_events.behavior_type==4)&(part_events.time>=chk_day)&(part_events.time<chk_day+pd.Timedelta(1,'d'))]\n",
    "\n",
    "    buy_users=len(buy_events.user_id.unique())\n",
    "    active_users=len(obs_events.user_id.unique())\n",
    "\n",
    "    print('%ddays, buy users %d, active users %d, ratio %.2f' % (during, buy_users, active_users, buy_users/active_users))\n",
    "\n",
    "for d in range(1,4):\n",
    "    count_active_users(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "about 20% active users will buy in next day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### action ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_evts_num=len(all_events)\n",
    "action_nums=all_events.groupby('behavior_type').count().item_id\n",
    "'action ratios %s ' % ((action_nums/all_evts_num)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_actions=all_events[['item_id','item_category','behavior_type','user_id']].pivot_table(index=['item_id','item_category'],\n",
    "                                                                                           columns='behavior_type',aggfunc='count').fillna(0)\n",
    "item_actions.columns=action_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_actions.sort_values('browsed',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_actions.sort_values('browsed',ascending=False)[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'total buy items %d, unpop items %d' %(len(item_actions[item_actions.bought>0]),len(item_actions[(item_actions.bought==1)&(item_actions.browsed==0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict active users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split users to 2 classes: buy or not-buy\n",
    "\n",
    "resample the not-buy user to build negative samples\n",
    "\n",
    "summary user's actions as features \n",
    "\n",
    "use lr to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obs_day=pd.Timestamp(year=2014,month=11,day=19)\n",
    "# buy_day=pd.Timestamp(year=2014,month=11,day=20)\n",
    "# test_day=pd.Timestamp(year=2014,month=11,day=21)\n",
    "\n",
    "# obs_events=part_events[(part_events.time>=obs_day)&(part_events.time<buy_day)]\n",
    "# obs_users=obs_events.user_id.unique()\n",
    "# buy_events=part_events[(part_events.behavior_type==4)&(part_events.time>=buy_day)&(part_events.time<test_day)]\n",
    "# buy_users=buy_events.user_id.unique()\n",
    "\n",
    "\n",
    "# obs_data=obs_events[['user_id','behavior_type','item_id']].pivot_table(index='user_id',columns='behavior_type',aggfunc='count').fillna(0)\n",
    "# obs_data['label']=[int(u in buy_users) for u in obs_data.index]\n",
    "\n",
    "# buy_data=obs_data[obs_data.label==1]\n",
    "# not_buy_data=obs_data[obs_data.label==0]\n",
    "\n",
    "# np.random.seed(1)\n",
    "\n",
    "# scores=[]\n",
    "# lr=LogisticRegression()\n",
    "# for i in range(3):\n",
    "#     not_buy_data=not_buy_data.loc[np.random.choice(not_buy_data.index,len(buy_data),replace=False)]\n",
    "\n",
    "#     train_data=pd.concat([buy_data,not_buy_data])\n",
    "#     X_train=train_data.drop('label',axis=1)\n",
    "#     y_train=train_data['label']\n",
    "\n",
    "    \n",
    "#     scores+=list(cross_val_score(lr,X_train,y_train,cv=5))\n",
    "    \n",
    "# np.mean(scores),np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obs_day=pd.Timestamp(year=2014,month=11,day=21)\n",
    "# buy_day=pd.Timestamp(year=2014,month=11,day=22)\n",
    "\n",
    "# obs_events=part_events[(part_events.time>=obs_day)&(part_events.time<buy_day)]\n",
    "# buy_events=part_events[(part_events.behavior_type==4)&(part_events.time>=buy_day)&(part_events.time<buy_day+pd.Timedelta(1,'d'))]\n",
    "\n",
    "\n",
    "# obs_data=obs_events[['user_id','behavior_type','item_id']].pivot_table(index='user_id',columns='behavior_type',aggfunc='count').fillna(0)\n",
    "# labels=lr.predict(obs_data)\n",
    "# probs=lr.predict_proba(obs_data)[:,1]\n",
    "# obs_data['label']=labels\n",
    "# obs_data['prob']=probs\n",
    "# len(obs_data),np.sum(obs_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(buy_events),len(buy_events.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(y_true,y_pred):\n",
    "    true_vals=set(y_true)\n",
    "    pred_vals=set(y_pred)\n",
    "    hits=len(list(filter(lambda x:x in true_vals,pred_vals)))\n",
    "    prec=hits/len(y_pred)\n",
    "    rec=hits/len(y_true)\n",
    "    return 2*prec*rec/(prec+rec),prec,rec\n",
    "\n",
    "score(buy_events.user_id.unique(),obs_data[obs_data.label==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score(buy_events.user_id.unique(),obs_data[obs_data.label==1].sort_values('prob',ascending=False)[:200].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get 30% accurate predicted buy users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp_tab=part_events[['item_id','behavior_type','time']]. \\\n",
    "#     pivot_table(index=['item_id'],columns=['behavior_type'],aggfunc='count').fillna(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp_tab.columns=action_types\n",
    "# tmp_tab['item_category']=[lambda i:all_items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buy actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_events.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_behaves=part_events[['user_id','item_id','behavior_type']].pivot_table(columns='behavior_type',index=['user_id','item_id'],aggfunc='sum').fillna(0)\n",
    "all_behaves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
